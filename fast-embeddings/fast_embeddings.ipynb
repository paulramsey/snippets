{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "i3DOtgkky0Gz",
      "metadata": {
        "id": "i3DOtgkky0Gz"
      },
      "source": [
        "<h1>Fast Embeddings</h1>\n",
        "\n",
        "AlloyDB provides a very useful [embedding() function](https://cloud.google.com/alloydb/docs/ai/work-with-embeddings#embedding-generation) that creates embeddings directly in the database. However, this function does not perform well when generating large batches of embeddings.\n",
        "\n",
        "This notebook walks you through generating [Vertex AI embeddings](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api) for the AlloyDB database used by the [GenWealth Demo App](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/sample-apps/genwealth). It uses [Beam/Dataflow](https://github.com/apache/beam/blob/master/examples/notebooks/beam-ml/data_preprocessing/vertex_ai_text_embeddings.ipynb) to significantly speed up the process of generating large batches of embeddings and storing them in AlloyDB vs using the native embedding() function."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YxXfErzY0eef",
      "metadata": {
        "id": "YxXfErzY0eef"
      },
      "source": [
        "<h2>Setup</h2>\n",
        "\n",
        "1. Install and import necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "Wh2lw8de1MmoQvwNN3l3MNG2",
      "metadata": {
        "executionInfo": {
          "elapsed": 25221,
          "status": "ok",
          "timestamp": 1721675504159,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "Wh2lw8de1MmoQvwNN3l3MNG2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "! pip install SQLAlchemy==2.0.29 --quiet\n",
        "! pip install google-cloud-alloydb-connector[pg8000]==1.0.0 --quiet\n",
        "! pip install apache_beam[gcp]>=2.53.0 --quiet\n",
        "\n",
        "\n",
        "from google.cloud.alloydb.connector import Connector\n",
        "import sqlalchemy\n",
        "from tabulate import tabulate\n",
        "import apache_beam as beam\n",
        "from apache_beam.ml.transforms.base import MLTransform\n",
        "from apache_beam.ml.transforms.embeddings.vertex_ai import VertexAITextEmbeddings\n",
        "\n",
        "import os, shutil\n",
        "import tempfile\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ieNt_O01dB",
      "metadata": {
        "id": "12ieNt_O01dB"
      },
      "source": [
        "2. Define variables to match your local environment.\n",
        ">This step assumes you have a secret stored in Secret Manager called `alloydb-secret`. You can use an alternate method to define your password if desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "P_FXOG-IuOut",
      "metadata": {
        "executionInfo": {
          "elapsed": 1225,
          "status": "ok",
          "timestamp": 1721675694622,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "P_FXOG-IuOut"
      },
      "outputs": [],
      "source": [
        "# GCP vars\n",
        "region = \"us-central1\"\n",
        "project_id = \"YOUR-PROJECT-ID\"\n",
        "\n",
        "# AlloyDB Vars\n",
        "cluster = \"alloydb-cluster\"\n",
        "instance = \"alloydb-instance\"\n",
        "database = \"ragdemos\"\n",
        "user = \"postgres\"\n",
        "password = !gcloud secrets versions access latest --secret=\"alloydb-secret\"\n",
        "password = str(password[0])\n",
        "\n",
        "# Embedding vars\n",
        "text_embedding_model_name = 'textembedding-gecko@003'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rIu_4lkK1P4y",
      "metadata": {
        "id": "rIu_4lkK1P4y"
      },
      "source": [
        "3. Setup the database connection to AlloyDB. This connector and pool will be used later in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "_hRuqOy9vCHf",
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1721675695944,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "_hRuqOy9vCHf"
      },
      "outputs": [],
      "source": [
        "# Define connector and pool\n",
        "connector = Connector()\n",
        "\n",
        "def getconn():\n",
        "    conn = connector.connect(\n",
        "        f\"projects/{project_id}/locations/{region}/clusters/{cluster}/instances/{instance}\",\n",
        "        \"pg8000\",\n",
        "        user=user,\n",
        "        password=password,\n",
        "        db=database,\n",
        "    )\n",
        "    return conn\n",
        "\n",
        "# create connection pool\n",
        "pool = sqlalchemy.create_engine(\n",
        "    \"postgresql+pg8000://\",\n",
        "    creator=getconn,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aP9hAgD_HJtJ",
      "metadata": {
        "id": "aP9hAgD_HJtJ"
      },
      "source": [
        "4. Retrieve the text data from AlloyDB that you want to embed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "zel3XhYuHGYZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 598,
          "status": "ok",
          "timestamp": 1721675699347,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "zel3XhYuHGYZ",
        "outputId": "f2aaeb59-c8b6-4f3a-8321-8f0de69bdadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running SQL query: \n",
            "    SELECT id, overview, analysis FROM embedding_test;\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# Store output in array of serializable dictionaries\n",
        "result_dicts = []\n",
        "\n",
        "# Define database query to get primary key plus text data to embed\n",
        "# Ensure you retrieve the id key to uniquely identify the row you are embedding\n",
        "sql = f\"\"\"\n",
        "    SELECT id, overview, analysis FROM embedding_test;\n",
        "    \"\"\"\n",
        "\n",
        "# Run the query\n",
        "print(f\"Running SQL query: {sql}\")\n",
        "with pool.connect() as db_conn:\n",
        "    # query database\n",
        "    result = db_conn.execute(sqlalchemy.text(sql))\n",
        "\n",
        "    for row in result:\n",
        "      result_dicts.append(dict(row._mapping))\n",
        "\n",
        "    db_conn.commit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H1XMSz6s1slF",
      "metadata": {
        "id": "H1XMSz6s1slF"
      },
      "source": [
        "5. Define helper function to updates embeddings in AlloyDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "_9JntzIVSu-j",
      "metadata": {
        "executionInfo": {
          "elapsed": 320,
          "status": "ok",
          "timestamp": 1721675722618,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "_9JntzIVSu-j"
      },
      "outputs": [],
      "source": [
        "# Helper function to update embeddings in AlloyDB\n",
        "def update_embeddings(_transformed_pcoll):\n",
        "\n",
        "  # Define the update query\n",
        "  sql = f\"\"\"\n",
        "    UPDATE embedding_test SET\n",
        "      overview_embedding = '{_transformed_pcoll['overview']}',\n",
        "      analysis_embedding = '{_transformed_pcoll['analysis']}'\n",
        "    WHERE id = {_transformed_pcoll['id']};\n",
        "    \"\"\"\n",
        "\n",
        "  # Run the query\n",
        "  with pool.connect() as db_conn:\n",
        "      # query database\n",
        "      result = db_conn.execute(sqlalchemy.text(sql))\n",
        "      db_conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "1RLSxkGEG0Ry",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 498580,
          "status": "ok",
          "timestamp": 1721673943342,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "1RLSxkGEG0Ry",
        "outputId": "88510970-8f3c-45c3-85bb-eb4c1c5268b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Union[Tuple[apache_beam.pvalue.PCollection[~MLTransformOutputT], apache_beam.pvalue.PCollection[apache_beam.pvalue.Row]], apache_beam.pvalue.PCollection[~MLTransformOutputT]] instead.\n",
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Union[Tuple[apache_beam.pvalue.PCollection[~MLTransformOutputT], apache_beam.pvalue.PCollection[apache_beam.pvalue.Row]], apache_beam.pvalue.PCollection[~MLTransformOutputT]] instead.\n",
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Union[Tuple[apache_beam.pvalue.PCollection[~MLTransformOutputT], apache_beam.pvalue.PCollection[apache_beam.pvalue.Row]], apache_beam.pvalue.PCollection[~MLTransformOutputT]] instead.\n",
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Union[Tuple[apache_beam.pvalue.PCollection[~MLTransformOutputT], apache_beam.pvalue.PCollection[apache_beam.pvalue.Row]], apache_beam.pvalue.PCollection[~MLTransformOutputT]] instead.\n"
          ]
        }
      ],
      "source": [
        "# Remove the temp file if it exists (throws an error otherwise)\n",
        "if os.path.exists(artifact_location):\n",
        "  shutil.rmtree(artifact_location)\n",
        "\n",
        "# Create a temp file for beam output\n",
        "artifact_location = tempfile.mkdtemp(prefix='vertex_ai')\n",
        "\n",
        "# Define the columns you want to embeding (overview and analysis in this case)\n",
        "embedding_transform = VertexAITextEmbeddings(\n",
        "    model_name=text_embedding_model_name, columns=['overview', 'analysis'], project=project_id)\n",
        "\n",
        "# Define the beam pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "  data_pcoll = (\n",
        "      pipeline\n",
        "      | \"CreateData\" >> beam.Create(result_dicts))\n",
        "  transformed_pcoll = (\n",
        "      data_pcoll\n",
        "      | \"MLTransform\" >> MLTransform(write_artifact_location=artifact_location).with_transform(embedding_transform))\n",
        "\n",
        "  # Update the embeddings in AlloyDB\n",
        "  transformed_pcoll | beam.Map(update_embeddings)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fast_embeddings",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
